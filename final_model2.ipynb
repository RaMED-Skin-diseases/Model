{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a2c353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.1+cu118\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu11, nvidia-cuda-cupti-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-runtime-cu11, nvidia-cudnn-cu11, nvidia-cufft-cu11, nvidia-curand-cu11, nvidia-cusolver-cu11, nvidia-cusparse-cu11, nvidia-nccl-cu11, nvidia-nvtx-cu11, sympy, triton, typing-extensions\n",
      "Required-by: accelerate, peft, torchaudio, torchvision, trl\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd3639b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (10.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39810ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (4.31.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.27.0\n",
      "    Uninstalling huggingface-hub-0.27.0:\n",
      "      Successfully uninstalled huggingface-hub-0.27.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.31.0\n",
      "    Uninstalling transformers-4.31.0:\n",
      "      Successfully uninstalled transformers-4.31.0\n",
      "Successfully installed huggingface-hub-0.30.2 tokenizers-0.21.1 transformers-4.51.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb62fe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 18:09:01.343625: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745424541.361178   17995 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745424541.367417   17995 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745424541.382924   17995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745424541.382955   17995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745424541.382957   17995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745424541.382958   17995 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-23 18:09:01.386901: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
    "from PIL import Image\n",
    "\n",
    "# Model name from Hugging Face\n",
    "repo_name = \"Jayanth2002/dinov2-base-finetuned-SkinDisease\"\n",
    "\n",
    "# Load the processor and model\n",
    "image_processor = AutoImageProcessor.from_pretrained(repo_name)\n",
    "model = AutoModelForImageClassification.from_pretrained(repo_name, trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7f9d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Psoriasis (Confidence: 92.87%)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = \"/home/rabieash/projects/GP/psoriasis-treatment-in-houston.jpg\"\n",
    "image = Image.open(image_path)\n",
    "inputs = image_processor(image.convert(\"RGB\"), return_tensors=\"pt\")\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "# Get predicted class index and its probability\n",
    "predicted_class_idx = probs.argmax(-1).item()\n",
    "confidence = probs[0, predicted_class_idx].item()\n",
    "\n",
    "# Class names\n",
    "class_names = [\n",
    "    'Basal Cell Carcinoma', 'Darier_s Disease', 'Epidermolysis Bullosa Pruriginosa',\n",
    "    'Hailey-Hailey Disease', 'Herpes Simplex', 'Impetigo', 'Larva Migrans',\n",
    "    'Leprosy Borderline', 'Leprosy Lepromatous', 'Leprosy Tuberculoid',\n",
    "    'Lichen Planus', 'Lupus Erythematosus Chronicus Discoides', 'Melanoma',\n",
    "    'Molluscum Contagiosum', 'Mycosis Fungoides', 'Neurofibromatosis',\n",
    "    'Papilomatosis Confluentes And Reticulate', 'Pediculosis Capitis',\n",
    "    'Pityriasis Rosea', 'Porokeratosis Actinic', 'Psoriasis', 'Tinea Corporis',\n",
    "    'Tinea Nigra', 'Tungiasis', 'actinic keratosis', 'dermatofibroma', 'nevus',\n",
    "    'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma',\n",
    "    'vascular lesion'\n",
    "]\n",
    "\n",
    "# Final prediction\n",
    "predicted_class_name = class_names[predicted_class_idx]\n",
    "print(f\"Predicted class: {predicted_class_name} (Confidence: {confidence:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b477b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_model1 = [\n",
    "    'Eczema',\n",
    "    'Melanoma',\n",
    "    'Atopic Dermatitis',\n",
    "    'Basal Cell Carcinoma',\n",
    "    'Melanocytic Nevi',\n",
    "    'Benign Keratosis'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9de727a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names_model2 = [\n",
    "    'Basal Cell Carcinoma', 'Darier_s Disease', 'Epidermolysis Bullosa Pruriginosa',\n",
    "    'Hailey-Hailey Disease', 'Herpes Simplex', 'Impetigo', 'Larva Migrans',\n",
    "    'Leprosy Borderline', 'Leprosy Lepromatous', 'Leprosy Tuberculoid',\n",
    "    'Lichen Planus', 'Lupus Erythematosus Chronicus Discoides', 'Melanoma',\n",
    "    'Molluscum Contagiosum', 'Mycosis Fungoides', 'Neurofibromatosis',\n",
    "    'Papilomatosis Confluentes And Reticulate', 'Pediculosis Capitis',\n",
    "    'Pityriasis Rosea', 'Porokeratosis Actinic', 'Psoriasis', 'Tinea Corporis',\n",
    "    'Tinea Nigra', 'Tungiasis', 'actinic keratosis', 'dermatofibroma', 'nevus',\n",
    "    'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma',\n",
    "    'vascular lesion'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eec3029",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageClassifierOutput' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)  \u001b[38;5;66;03m# Start with common size\u001b[39;00m\n\u001b[1;32m      2\u001b[0m output \u001b[38;5;241m=\u001b[39m model(dummy_input)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageClassifierOutput' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224)  # Start with common size\n",
    "output = model(dummy_input)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f7e7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 31])\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Instead of output.shape, you should do:\n",
    "print(output.logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b64193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/transformers/models/dinov2/modeling_dinov2.py:165: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if num_channels != self.num_channels:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved as 'model_mobile.pt' and ready for mobile app!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Make sure model is in eval mode\n",
    "model.eval()\n",
    "\n",
    "# 2. Create dummy input (same as real input size)\n",
    "example_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# 3. Wrap the model to return only logits\n",
    "class WrappedModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x).logits  # Only return logits\n",
    "\n",
    "# 4. Wrap your original model\n",
    "wrapped_model = WrappedModel(model)\n",
    "\n",
    "# 5. Trace it\n",
    "traced_model = torch.jit.trace(wrapped_model, example_input)\n",
    "\n",
    "# 6. Save it\n",
    "traced_model.save('model_mobile.pt')\n",
    "\n",
    "print(\"✅ Model saved as 'model_mobile.pt' and ready for mobile app!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28f4c179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Psoriasis (Confidence: 92.87%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# 1. Load the traced model\n",
    "model1 = torch.jit.load('model_mobile.pt')\n",
    "model1.eval()  # Make sure the model is in evaluation mode\n",
    "\n",
    "# 2. Preprocess the image (same preprocessing steps as used during training)\n",
    "image_path = \"/home/rabieash/projects/GP/psoriasis-treatment-in-houston.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    logits = model1(inputs['pixel_values'])\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "# Get predicted class index and its probability\n",
    "predicted_class_idx = probs.argmax(-1).item()\n",
    "confidence = probs[0, predicted_class_idx].item()\n",
    "\n",
    "# Class names\n",
    "class_names = [\n",
    "    'Basal Cell Carcinoma', 'Darier_s Disease', 'Epidermolysis Bullosa Pruriginosa',\n",
    "    'Hailey-Hailey Disease', 'Herpes Simplex', 'Impetigo', 'Larva Migrans',\n",
    "    'Leprosy Borderline', 'Leprosy Lepromatous', 'Leprosy Tuberculoid',\n",
    "    'Lichen Planus', 'Lupus Erythematosus Chronicus Discoides', 'Melanoma',\n",
    "    'Molluscum Contagiosum', 'Mycosis Fungoides', 'Neurofibromatosis',\n",
    "    'Papilomatosis Confluentes And Reticulate', 'Pediculosis Capitis',\n",
    "    'Pityriasis Rosea', 'Porokeratosis Actinic', 'Psoriasis', 'Tinea Corporis',\n",
    "    'Tinea Nigra', 'Tungiasis', 'actinic keratosis', 'dermatofibroma', 'nevus',\n",
    "    'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma',\n",
    "    'vascular lesion'\n",
    "]\n",
    "\n",
    "# Final prediction\n",
    "predicted_class_name = class_names[predicted_class_idx]\n",
    "print(f\"Predicted class: {predicted_class_name} (Confidence: {confidence:.2%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f92f1",
   "metadata": {},
   "source": [
    "so the pretrained preprocessing is better than manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611eb6bf",
   "metadata": {},
   "source": [
    "***trying manually preprocessing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b20ed77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Psoriasis (Confidence: 91.63%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# 1. Load the traced model\n",
    "model2 = torch.jit.load('model_mobile.pt')\n",
    "model2.eval()  # Make sure the model is in evaluation mode\n",
    "\n",
    "# 2. Preprocess the image (same preprocessing steps as used during training)\n",
    "image_path = \"/home/rabieash/projects/GP/psoriasis-treatment-in-houston.jpg\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Define the transformations (adjust if needed for your model)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),  # Resize image to 256x256 (can adjust if needed)\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization values\n",
    "])\n",
    "\n",
    "# Apply the preprocessing to the image\n",
    "input_tensor = preprocess(image.convert(\"RGB\"))\n",
    "input_batch = input_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# 3. Run inference\n",
    "with torch.no_grad():  # No need for gradients during inference\n",
    "    output = model2(input_batch)  # Forward pass through the model\n",
    "\n",
    "# 4. Convert logits to probabilities\n",
    "probs = F.softmax(output, dim=-1)\n",
    "\n",
    "# 5. Get predicted class index and its probability\n",
    "predicted_class_idx = probs.argmax(-1).item()\n",
    "confidence = probs[0, predicted_class_idx].item()\n",
    "\n",
    "# 6. Class names (same as before)\n",
    "class_names = [\n",
    "    'Basal Cell Carcinoma', 'Darier_s Disease', 'Epidermolysis Bullosa Pruriginosa',\n",
    "    'Hailey-Hailey Disease', 'Herpes Simplex', 'Impetigo', 'Larva Migrans',\n",
    "    'Leprosy Borderline', 'Leprosy Lepromatous', 'Leprosy Tuberculoid',\n",
    "    'Lichen Planus', 'Lupus Erythematosus Chronicus Discoides', 'Melanoma',\n",
    "    'Molluscum Contagiosum', 'Mycosis Fungoides', 'Neurofibromatosis',\n",
    "    'Papilomatosis Confluentes And Reticulate', 'Pediculosis Capitis',\n",
    "    'Pityriasis Rosea', 'Porokeratosis Actinic', 'Psoriasis', 'Tinea Corporis',\n",
    "    'Tinea Nigra', 'Tungiasis', 'actinic keratosis', 'dermatofibroma', 'nevus',\n",
    "    'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma',\n",
    "    'vascular lesion'\n",
    "]\n",
    "\n",
    "# 7. Final prediction\n",
    "predicted_class_name = class_names[predicted_class_idx]\n",
    "print(f\"Predicted class: {predicted_class_name} (Confidence: {confidence:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1497085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Quantized and saved model as 'model_mobile_quantized.pt' ready for mobile app!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Make sure model is in eval mode\n",
    "model.eval()\n",
    "\n",
    "# 2. Quantize the model (dynamic quantization)\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model,  # your original model\n",
    "    {torch.nn.Linear},  # quantize only Linear layers\n",
    "    dtype=torch.qint8  # use int8 for maximum size reduction\n",
    ")\n",
    "\n",
    "# 3. (Optional) Wrap the model to control output if needed\n",
    "class WrappedModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # No `.logits` here because output is already Tensor\n",
    "\n",
    "# 4. Wrap your quantized model\n",
    "wrapped_model = WrappedModel(quantized_model)\n",
    "\n",
    "# 5. Create dummy input (must match input shape: batch_size, channels, height, width)\n",
    "example_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# 6. Trace the model\n",
    "traced_model = torch.jit.trace(wrapped_model, example_input)\n",
    "\n",
    "# 7. Save the traced + quantized model\n",
    "traced_model.save('model_mobile_quantized.pt')\n",
    "\n",
    "print(\"✅ Quantized and saved model as 'model_mobile_quantized.pt' ready for mobile app!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8ceed5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Psoriasis (Confidence: 92.87%)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# 1. Load the traced quantized model\n",
    "model1 = torch.jit.load('model_mobile_quantized.pt')\n",
    "model1.eval()  # Important: eval mode\n",
    "\n",
    "# 2. Preprocess the image\n",
    "image_path = \"/home/rabieash/projects/GP/psoriasis-treatment-in-houston.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "\n",
    "\n",
    "# 3. Run inference\n",
    "with torch.no_grad():\n",
    "    logits = model1(inputs['pixel_values'])\n",
    "\n",
    "# 4. Convert logits to probabilities\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "# 5. Get predicted class index and its probability\n",
    "predicted_class_idx = probs.argmax(-1).item()\n",
    "confidence = probs[0, predicted_class_idx].item()\n",
    "\n",
    "# 6. Class names\n",
    "class_names = [\n",
    "    'Basal Cell Carcinoma', 'Darier_s Disease', 'Epidermolysis Bullosa Pruriginosa',\n",
    "    'Hailey-Hailey Disease', 'Herpes Simplex', 'Impetigo', 'Larva Migrans',\n",
    "    'Leprosy Borderline', 'Leprosy Lepromatous', 'Leprosy Tuberculoid',\n",
    "    'Lichen Planus', 'Lupus Erythematosus Chronicus Discoides', 'Melanoma',\n",
    "    'Molluscum Contagiosum', 'Mycosis Fungoides', 'Neurofibromatosis',\n",
    "    'Papilomatosis Confluentes And Reticulate', 'Pediculosis Capitis',\n",
    "    'Pityriasis Rosea', 'Porokeratosis Actinic', 'Psoriasis', 'Tinea Corporis',\n",
    "    'Tinea Nigra', 'Tungiasis', 'actinic keratosis', 'dermatofibroma', 'nevus',\n",
    "    'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma',\n",
    "    'vascular lesion'\n",
    "]\n",
    "\n",
    "# 7. Final prediction\n",
    "predicted_class_name = class_names[predicted_class_idx]\n",
    "print(f\"Predicted class: {predicted_class_name} (Confidence: {confidence:.2%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5de46c",
   "metadata": {},
   "source": [
    "***finally use that***\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
