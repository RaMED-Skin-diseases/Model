{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a434f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (2.5.1+cu118)\n",
      "Requirement already satisfied: torchvision in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (0.20.1+cu118)\n",
      "Requirement already satisfied: tensorflow in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (2.19.0)\n",
      "Requirement already satisfied: pillow in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (10.2.0)\n",
      "Requirement already satisfied: matplotlib in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: numpy in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (1.26.3)\n",
      "Requirement already satisfied: filelock in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (11.8.86)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: rich in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision tensorflow pillow matplotlib numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de72bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Force CPU-only mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fde818c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 20:33:35.796748: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746293615.831484    5635 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746293615.841070    5635 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746293615.867272    5635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746293615.867360    5635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746293615.867363    5635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746293615.867364    5635 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-03 20:33:35.877039: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceeffe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Configure GPU settings at the very beginning\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'  # Allow GPU memory growth\n",
    "\n",
    "# Initialize TensorFlow in a separate cell before any model loading\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(\"GPU configuration error (memory growth):\", e)\n",
    "except Exception as e:\n",
    "    print(\"GPU detection error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60d87fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDiseaseClassifier:\n",
    "    def __init__(self):\n",
    "        print(\"Initializing models...\")\n",
    "        \n",
    "        # Initialize TensorFlow model first\n",
    "        try:\n",
    "            print(\"Loading TensorFlow model...\")\n",
    "            self.model1 = tf.keras.models.load_model('final_model.h5')\n",
    "            self.feature_extractor = tf.keras.applications.ResNet50(\n",
    "                weights='imagenet', \n",
    "                include_top=False, \n",
    "                pooling='avg'\n",
    "            )\n",
    "            print(\"TensorFlow model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(\"Error loading TensorFlow model:\", e)\n",
    "            raise\n",
    "\n",
    "        # Then initialize PyTorch model\n",
    "        try:\n",
    "            print(\"Loading PyTorch model...\")\n",
    "            self.model2 = torch.jit.load('model_mobile_quantized.pt')\n",
    "            self.model2.eval()\n",
    "            print(\"PyTorch model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(\"Error loading PyTorch model:\", e)\n",
    "            raise\n",
    "\n",
    "        # Class names\n",
    "        self.class_names_model1 = [\n",
    "            'Eczema', 'Melanoma', 'Atopic Dermatitis', \n",
    "            'Basal Cell Carcinoma', 'Melanocytic Nevi', 'Benign Keratosis'\n",
    "        ]\n",
    "        \n",
    "        self.class_names_model2 = [\n",
    "            'Basal Cell Carcinoma', 'Darier_s Disease', 'Epidermolysis Bullosa Pruriginosa',\n",
    "            'Hailey-Hailey Disease', 'Herpes Simplex', 'Impetigo', 'Larva Migrans',\n",
    "            'Leprosy Borderline', 'Leprosy Lepromatous', 'Leprosy Tuberculoid',\n",
    "            'Lichen Planus', 'Lupus Erythematosus Chronicus Discoides', 'Melanoma',\n",
    "            'Molluscum Contagiosum', 'Mycosis Fungoides', 'Neurofibromatosis',\n",
    "            'Papilomatosis Confluentes And Reticulate', 'Pediculosis Capitis',\n",
    "            'Pityriasis Rosea', 'Porokeratosis Actinic', 'Psoriasis', 'Tinea Corporis',\n",
    "            'Tinea Nigra', 'Tungiasis', 'actinic keratosis', 'dermatofibroma', 'nevus',\n",
    "            'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma',\n",
    "            'vascular lesion'\n",
    "        ]\n",
    "\n",
    "    def preprocess_for_model1(self, image):\n",
    "        \"\"\"Preprocess image for TensorFlow ResNet50 model\"\"\"\n",
    "        image = image.resize((224, 224))\n",
    "        image_array = img_to_array(image)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        return preprocess_input(image_array)\n",
    "\n",
    "    def preprocess_for_model2(self, image):\n",
    "        \"\"\"Preprocess image for PyTorch DINOv2 model\"\"\"\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        return preprocess(image.convert(\"RGB\")).unsqueeze(0)\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Run parallel prediction on both models\"\"\"\n",
    "        # Load image\n",
    "        pil_image = Image.open(image_path)\n",
    "        \n",
    "        # Run model1 (TensorFlow)\n",
    "        try:\n",
    "            tf_input = self.preprocess_for_model1(pil_image)\n",
    "            features = self.feature_extractor.predict(tf_input)\n",
    "            model1_probs = self.model1.predict(features)[0]\n",
    "            model1_class_idx = np.argmax(model1_probs)\n",
    "            model1_confidence = model1_probs[model1_class_idx]\n",
    "            model1_class = self.class_names_model1[model1_class_idx]\n",
    "        except Exception as e:\n",
    "            print(\"TensorFlow prediction error:\", e)\n",
    "            model1_class = \"Error\"\n",
    "            model1_confidence = 0.0\n",
    "            model1_probs = []\n",
    "        \n",
    "        # Run model2 (PyTorch)\n",
    "        try:\n",
    "            pt_input = self.preprocess_for_model2(pil_image)\n",
    "            with torch.no_grad():\n",
    "                model2_output = self.model2(pt_input)\n",
    "            model2_probs = F.softmax(model2_output, dim=-1)[0]\n",
    "            model2_class_idx = model2_probs.argmax(-1).item()\n",
    "            model2_confidence = model2_probs[model2_class_idx].item()\n",
    "            model2_class = self.class_names_model2[model2_class_idx]\n",
    "        except Exception as e:\n",
    "            print(\"PyTorch prediction error:\", e)\n",
    "            model2_class = \"Error\"\n",
    "            model2_confidence = 0.0\n",
    "            model2_probs = []\n",
    "        \n",
    "        return {\n",
    "            'model1': {\n",
    "                'class': model1_class,\n",
    "                'confidence': float(model1_confidence),\n",
    "                'all_probs': model1_probs.tolist() if len(model1_probs) > 0 else []\n",
    "            },\n",
    "            'model2': {\n",
    "                'class': model2_class,\n",
    "                'confidence': model2_confidence,\n",
    "                'all_probs': model2_probs.tolist() if torch.is_tensor(model2_probs) else []\n",
    "            },\n",
    "            'combined': self.combine_results(\n",
    "                model1_class, model1_confidence,\n",
    "                model2_class, model2_confidence\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def combine_results(self, class1, conf1, class2, conf2):\n",
    "        \"\"\"Class-aware combination logic\"\"\"\n",
    "        # Known conflict cases\n",
    "        conflict_pairs = {\n",
    "            ('Eczema', 'Psoriasis'): 'Psoriasis',\n",
    "            ('Benign Keratosis', 'actinic keratosis'): 'actinic keratosis',\n",
    "            ('Melanocytic Nevi', 'Melanoma'): 'Melanoma',\n",
    "            ('Atopic Dermatitis', 'Eczema'): 'Eczema'\n",
    "        }\n",
    "        \n",
    "        # Check both orderings of class pairs\n",
    "        if (class1, class2) in conflict_pairs:\n",
    "            correct_class = conflict_pairs[(class1, class2)]\n",
    "            return {\n",
    "                'final_class': correct_class, \n",
    "                'confidence': max(conf1, conf2),\n",
    "                'source': 'expert_rules'\n",
    "            }\n",
    "        elif (class2, class1) in conflict_pairs:\n",
    "            correct_class = conflict_pairs[(class2, class1)]\n",
    "            return {\n",
    "                'final_class': correct_class,\n",
    "                'confidence': max(conf1, conf2),\n",
    "                'source': 'expert_rules'\n",
    "            }\n",
    "        \n",
    "        # Default confidence-based approach with preference to model2 (DINOv2)\n",
    "        if conf1 > conf2 + 0.15:  # If model1 is significantly more confident\n",
    "            return {\n",
    "                'final_class': class1,\n",
    "                'confidence': conf1,\n",
    "                'source': 'model1'\n",
    "            }\n",
    "        else:  # Default to model2's prediction\n",
    "            return {\n",
    "                'final_class': class2,\n",
    "                'confidence': conf2,\n",
    "                'source': 'model2'\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a120459e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models...\n",
      "Loading TensorFlow model...\n",
      "TensorFlow model loaded successfully\n",
      "Loading PyTorch model...\n",
      "PyTorch model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "classifier = SkinDiseaseClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "90d77cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n"
     ]
    }
   ],
   "source": [
    "# Test prediction\n",
    "image_path = '/home/rabieash/projects/GP/Kareem_eczema.jpeg'\n",
    "result = classifier.predict(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3b3d0676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prediction Results ===\n",
      "ResNet50 Prediction: Atopic Dermatitis (67.1%)\n",
      "DINOv2 Prediction: Impetigo (48.3%)\n",
      "Final Decision: Atopic Dermatitis (67.1%) [Source: model1]\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"\\n=== Prediction Results ===\")\n",
    "print(\"ResNet50 Prediction:\", result['model1']['class'], f\"({result['model1']['confidence']:.1%})\")\n",
    "print(\"DINOv2 Prediction:\", result['model2']['class'], f\"({result['model2']['confidence']:.1%})\")\n",
    "print(\"Final Decision:\", result['combined']['final_class'], \n",
    "      f\"({result['combined']['confidence']:.1%})\",\n",
    "      f\"[Source: {result['combined']['source']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187ad47",
   "metadata": {},
   "source": [
    "**l7ad hna**---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5bfec5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib\n",
      "Successfully installed joblib-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71259244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:29:08.002323: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746300548.065555   10307 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746300548.089911   10307 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746300548.234231   10307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746300548.234294   10307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746300548.234297   10307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746300548.234298   10307 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-03 22:29:08.259859: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dill\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from pathlib import Path\n",
    "\n",
    "class CombinedSkinModel:\n",
    "    def __init__(self, tf_model_path, torch_model_path, class_names1, class_names2, conflict_rules):\n",
    "        # Store paths instead of loaded models\n",
    "        self.tf_model_path = tf_model_path\n",
    "        self.torch_model_path = torch_model_path\n",
    "        self.class_names_model1 = class_names1\n",
    "        self.class_names_model2 = class_names2\n",
    "        self.conflict_rules = conflict_rules\n",
    "        \n",
    "        # Initialize models as None (will lazy-load when needed)\n",
    "        self._tf_model = None\n",
    "        self._torch_model = None\n",
    "        self._feature_extractor = None\n",
    "    \n",
    "    @property\n",
    "    def tf_model(self):\n",
    "        if self._tf_model is None:\n",
    "            self._tf_model = tf.keras.models.load_model(self.tf_model_path)\n",
    "        return self._tf_model\n",
    "    \n",
    "    @property\n",
    "    def torch_model(self):\n",
    "        if self._torch_model is None:\n",
    "            self._torch_model = torch.jit.load(self.torch_model_path)\n",
    "            self._torch_model.eval()\n",
    "        return self._torch_model\n",
    "    \n",
    "    @property\n",
    "    def feature_extractor(self):\n",
    "        if self._feature_extractor is None:\n",
    "            self._feature_extractor = tf.keras.applications.ResNet50(\n",
    "                weights='imagenet', \n",
    "                include_top=False, \n",
    "                pooling='avg'\n",
    "            )\n",
    "        return self._feature_extractor\n",
    "    \n",
    "    def preprocess_for_model1(self, image):\n",
    "        \"\"\"Preprocess image for TensorFlow ResNet50 model\"\"\"\n",
    "        image = image.resize((224, 224))\n",
    "        image_array = img_to_array(image)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        return preprocess_input(image_array)\n",
    "\n",
    "    def preprocess_for_model2(self, image):\n",
    "        \"\"\"Preprocess image for PyTorch DINOv2 model\"\"\"\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        return preprocess(image.convert(\"RGB\")).unsqueeze(0)\n",
    "    \n",
    "    def combine_results(self, class1, conf1, class2, conf2):\n",
    "        \"\"\"Class-aware combination logic\"\"\"\n",
    "        # Check both orderings of class pairs\n",
    "        if (class1, class2) in self.conflict_rules:\n",
    "            correct_class = self.conflict_rules[(class1, class2)]\n",
    "            return {\n",
    "                'final_class': correct_class, \n",
    "                'confidence': max(conf1, conf2),\n",
    "                'source': 'expert_rules'\n",
    "            }\n",
    "        elif (class2, class1) in self.conflict_rules:\n",
    "            correct_class = self.conflict_rules[(class2, class1)]\n",
    "            return {\n",
    "                'final_class': correct_class,\n",
    "                'confidence': max(conf1, conf2),\n",
    "                'source': 'expert_rules'\n",
    "            }\n",
    "        \n",
    "        # Default confidence-based approach with preference to model2 (DINOv2)\n",
    "        if conf1 > conf2 + 0.15:  # If model1 is significantly more confident\n",
    "            return {\n",
    "                'final_class': class1,\n",
    "                'confidence': conf1,\n",
    "                'source': 'model1'\n",
    "            }\n",
    "        else:  # Default to model2's prediction\n",
    "            return {\n",
    "                'final_class': class2,\n",
    "                'confidence': conf2,\n",
    "                'source': 'model2'\n",
    "            }\n",
    "    \n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Run parallel prediction on both models\"\"\"\n",
    "        # Load image\n",
    "        pil_image = Image.open(image_path)\n",
    "        \n",
    "        # Run model1 (TensorFlow)\n",
    "        try:\n",
    "            tf_input = self.preprocess_for_model1(pil_image)\n",
    "            features = self.feature_extractor.predict(tf_input)\n",
    "            model1_probs = self.tf_model.predict(features)[0]\n",
    "            model1_class_idx = np.argmax(model1_probs)\n",
    "            model1_confidence = model1_probs[model1_class_idx]\n",
    "            model1_class = self.class_names_model1[model1_class_idx]\n",
    "        except Exception as e:\n",
    "            print(\"TensorFlow prediction error:\", e)\n",
    "            model1_class = \"Error\"\n",
    "            model1_confidence = 0.0\n",
    "            model1_probs = []\n",
    "        \n",
    "        # Run model2 (PyTorch)\n",
    "        try:\n",
    "            pt_input = self.preprocess_for_model2(pil_image)\n",
    "            with torch.no_grad():\n",
    "                model2_output = self.torch_model(pt_input)\n",
    "            model2_probs = F.softmax(model2_output, dim=-1)[0]\n",
    "            model2_class_idx = model2_probs.argmax(-1).item()\n",
    "            model2_confidence = model2_probs[model2_class_idx].item()\n",
    "            model2_class = self.class_names_model2[model2_class_idx]\n",
    "        except Exception as e:\n",
    "            print(\"PyTorch prediction error:\", e)\n",
    "            model2_class = \"Error\"\n",
    "            model2_confidence = 0.0\n",
    "            model2_probs = []\n",
    "        \n",
    "        return {\n",
    "            'model1': {\n",
    "                'class': model1_class,\n",
    "                'confidence': float(model1_confidence),\n",
    "                'all_probs': model1_probs.tolist() if len(model1_probs) > 0 else []\n",
    "            },\n",
    "            'model2': {\n",
    "                'class': model2_class,\n",
    "                'confidence': model2_confidence,\n",
    "                'all_probs': model2_probs.tolist() if torch.is_tensor(model2_probs) else []\n",
    "            },\n",
    "            'combined': self.combine_results(\n",
    "                model1_class, model1_confidence,\n",
    "                model2_class, model2_confidence\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"Custom save method that handles both models\"\"\"\n",
    "        # Create a temporary directory\n",
    "        temp_dir = Path(path).with_suffix('.tmp')\n",
    "        temp_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save TensorFlow model with proper extension\n",
    "        tf_model_path = temp_dir / 'tf_model.keras'  # Using recommended .keras extension\n",
    "        self.tf_model.save(tf_model_path)\n",
    "        \n",
    "        # Save PyTorch model\n",
    "        torch_model_path = temp_dir / 'torch_model.pt'\n",
    "        torch.jit.save(self.torch_model, torch_model_path)\n",
    "        \n",
    "        # Save the wrapper's state (excluding the models)\n",
    "        state = {\n",
    "            'tf_model_path': str(tf_model_path.absolute()),\n",
    "            'torch_model_path': str(torch_model_path.absolute()),\n",
    "            'class_names1': self.class_names_model1,\n",
    "            'class_names2': self.class_names_model2,\n",
    "            'conflict_rules': self.conflict_rules\n",
    "        }\n",
    "        \n",
    "        with open(path, 'wb') as f:\n",
    "            dill.dump(state, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\"Custom load method\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            state = dill.load(f)\n",
    "        \n",
    "        # For TensorFlow model, use either:\n",
    "        # Option 1: If saved as .keras\n",
    "        tf_model = tf.keras.models.load_model(state['tf_model_path'])\n",
    "        \n",
    "        # Option 2: If you need to support older .h5 format\n",
    "        # tf_model = tf.keras.models.load_model(state['tf_model_path'], compile=False)\n",
    "        \n",
    "        return cls(\n",
    "            tf_model_path=state['tf_model_path'],\n",
    "            torch_model_path=state['torch_model_path'],\n",
    "            class_names1=state['class_names1'],\n",
    "            class_names2=state['class_names2'],\n",
    "            conflict_rules=state['conflict_rules']\n",
    "        )\n",
    "\n",
    "# ====== CONFIGURATION ======\n",
    "CLASS_NAMES_MODEL1 = [\n",
    "    'Eczema', 'Melanoma', 'Atopic Dermatitis', \n",
    "    'Basal Cell Carcinoma', 'Melanocytic Nevi', 'Benign Keratosis'\n",
    "]\n",
    "\n",
    "CLASS_NAMES_MODEL2 = [\n",
    "    'Basal Cell Carcinoma', 'Darier_s Disease', 'Epidermolysis Bullosa Pruriginosa',\n",
    "    'Hailey-Hailey Disease', 'Herpes Simplex', 'Impetigo', 'Larva Migrans',\n",
    "    'Leprosy Borderline', 'Leprosy Lepromatous', 'Leprosy Tuberculoid',\n",
    "    'Lichen Planus', 'Lupus Erythematosus Chronicus Discoides', 'Melanoma',\n",
    "    'Molluscum Contagiosum', 'Mycosis Fungoides', 'Neurofibromatosis',\n",
    "    'Papilomatosis Confluentes And Reticulate', 'Pediculosis Capitis',\n",
    "    'Pityriasis Rosea', 'Porokeratosis Actinic', 'Psoriasis', 'Tinea Corporis',\n",
    "    'Tinea Nigra', 'Tungiasis', 'actinic keratosis', 'dermatofibroma', 'nevus',\n",
    "    'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma',\n",
    "    'vascular lesion'\n",
    "]\n",
    "\n",
    "CONFLICT_RULES = {\n",
    "    ('Eczema', 'Psoriasis'): 'Psoriasis',\n",
    "    ('Benign Keratosis', 'actinic keratosis'): 'actinic keratosis',\n",
    "    ('Melanocytic Nevi', 'Melanoma'): 'Melanoma',\n",
    "    ('Atopic Dermatitis', 'Eczema'): 'Eczema'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87e6b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== INITIALIZE AND SAVE ======\n",
    "combined_model = CombinedSkinModel(\n",
    "    tf_model_path='final_model.h5',\n",
    "    torch_model_path='model_mobile_quantized.pt',\n",
    "    class_names1=CLASS_NAMES_MODEL1,\n",
    "    class_names2=CLASS_NAMES_MODEL2,\n",
    "    conflict_rules=CONFLICT_RULES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "927373ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "combined_model.save('combined_skin_model.dill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca8e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746300594.491221   10307 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4057 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746300598.173183   10396 service.cc:152] XLA service 0x7efda0003380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746300598.173315   10396 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-05-03 22:29:58.276533: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "E0000 00:00:1746300598.884928   10396 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "E0000 00:00:1746300598.939536   10396 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-05-03 22:29:58.948381: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-05-03 22:29:58.948465: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow prediction error: Graph execution error:\n",
      "\n",
      "Detected at node StatefulPartitionedCall defined at (most recent call last):\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "\n",
      "  File \"/tmp/ipykernel_10307/766061882.py\", line 3, in <module>\n",
      "\n",
      "  File \"/tmp/ipykernel_10307/2932695494.py\", line 107, in predict\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 560, in predict\n",
      "\n",
      "  File \"/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 259, in one_step_on_data_distributed\n",
      "\n",
      "DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_data_distributed_5181]\n",
      "{'model1': {'class': 'Error', 'confidence': 0.0, 'all_probs': []}, 'model2': {'class': 'Psoriasis', 'confidence': 0.9859046339988708, 'all_probs': [3.990086838712159e-07, 0.005065029487013817, 0.0016546512488275766, 6.48167528538579e-08, 1.0572923656582134e-06, 7.748898497084156e-06, 0.002843110356479883, 0.00010288229532307014, 5.035272261011414e-05, 7.750517397653311e-06, 0.0004769971710629761, 9.965447679860517e-05, 3.1715401291876333e-06, 5.040797077526804e-07, 3.3116859299298085e-07, 4.998788938337384e-09, 3.421781229917542e-06, 6.711125593028555e-07, 0.0001643779978621751, 4.230448666930897e-06, 0.9859046339988708, 0.0035952264443039894, 2.6393394136903225e-07, 1.492489445809042e-06, 1.261279010122962e-07, 8.566883025196148e-08, 1.924774863937273e-07, 2.998209765792126e-06, 2.2843114493298344e-06, 6.121448222984327e-06, 2.0301388303778367e-07]}, 'combined': {'final_class': 'Psoriasis', 'confidence': 0.9859046339988708, 'source': 'model2'}}\n"
     ]
    }
   ],
   "source": [
    "# Load and test\n",
    "loaded_model = CombinedSkinModel.load('combined_skin_model.dill')\n",
    "result = loaded_model.predict('/home/rabieash/projects/GP/Psoriasis_copy.original.width-320.jpg')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d92b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prediction Results ===\n",
      "ResNet50 Prediction: Error (0.0%)\n",
      "DINOv2 Prediction: Psoriasis (98.6%)\n",
      "Final Decision: Psoriasis (98.6%) [Source: model2]\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"\\n=== Prediction Results ===\")\n",
    "print(\"ResNet50 Prediction:\", result['model1']['class'], f\"({result['model1']['confidence']:.1%})\")\n",
    "print(\"DINOv2 Prediction:\", result['model2']['class'], f\"({result['model2']['confidence']:.1%})\")\n",
    "print(\"Final Decision:\", result['combined']['final_class'], \n",
    "      f\"({result['combined']['confidence']:.1%})\",\n",
    "      f\"[Source: {result['combined']['source']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df632f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:44:52.781359: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746301492.804734   10716 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746301492.811756   10716 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746301492.839420   10716 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746301492.839442   10716 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746301492.839444   10716 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746301492.839445   10716 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-03 22:44:52.846863: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dill\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from pathlib import Path\n",
    "\n",
    "class CombinedSkinModel:\n",
    "    def __init__(self, tf_model=None, torch_model=None, class_names1=None, class_names2=None, conflict_rules=None):\n",
    "        self._tf_model = tf_model\n",
    "        self._torch_model = torch_model\n",
    "        self.class_names_model1 = class_names1 or []\n",
    "        self.class_names_model2 = class_names2 or []\n",
    "        self.conflict_rules = conflict_rules or {}\n",
    "        self._feature_extractor = None\n",
    "\n",
    "    @property\n",
    "    def tf_model(self):\n",
    "        if self._tf_model is None:\n",
    "            raise ValueError(\"TensorFlow model not loaded\")\n",
    "        return self._tf_model\n",
    "\n",
    "    @property\n",
    "    def torch_model(self):\n",
    "        if self._torch_model is None:\n",
    "            raise ValueError(\"PyTorch model not loaded\")\n",
    "        return self._torch_model\n",
    "\n",
    "    @property\n",
    "    def feature_extractor(self):\n",
    "        if self._feature_extractor is None:\n",
    "            self._feature_extractor = tf.keras.applications.ResNet50(\n",
    "                weights='imagenet', \n",
    "                include_top=False, \n",
    "                pooling='avg'\n",
    "            )\n",
    "        return self._feature_extractor\n",
    "\n",
    "    def preprocess_for_model1(self, image):\n",
    "        \"\"\"Preprocess image for TensorFlow ResNet50 model\"\"\"\n",
    "        image = image.resize((224, 224))\n",
    "        image_array = img_to_array(image)\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "        return preprocess_input(image_array)\n",
    "\n",
    "    def preprocess_for_model2(self, image):\n",
    "        \"\"\"Preprocess image for PyTorch DINOv2 model\"\"\"\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        return preprocess(image.convert(\"RGB\")).unsqueeze(0)\n",
    "    \n",
    "    def combine_results(self, class1, conf1, class2, conf2):\n",
    "        \"\"\"Class-aware combination logic\"\"\"\n",
    "        # Check both orderings of class pairs\n",
    "        if (class1, class2) in self.conflict_rules:\n",
    "            correct_class = self.conflict_rules[(class1, class2)]\n",
    "            return {\n",
    "                'final_class': correct_class, \n",
    "                'confidence': max(conf1, conf2),\n",
    "                'source': 'expert_rules'\n",
    "            }\n",
    "        elif (class2, class1) in self.conflict_rules:\n",
    "            correct_class = self.conflict_rules[(class2, class1)]\n",
    "            return {\n",
    "                'final_class': correct_class,\n",
    "                'confidence': max(conf1, conf2),\n",
    "                'source': 'expert_rules'\n",
    "            }\n",
    "        \n",
    "        # Default confidence-based approach with preference to model2 (DINOv2)\n",
    "        if conf1 > conf2 + 0.15:  # If model1 is significantly more confident\n",
    "            return {\n",
    "                'final_class': class1,\n",
    "                'confidence': conf1,\n",
    "                'source': 'model1'\n",
    "            }\n",
    "        else:  # Default to model2's prediction\n",
    "            return {\n",
    "                'final_class': class2,\n",
    "                'confidence': conf2,\n",
    "                'source': 'model2'\n",
    "            }\n",
    "    \n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Run parallel prediction on both models\"\"\"\n",
    "        # Load image\n",
    "        pil_image = Image.open(image_path)\n",
    "        \n",
    "        # Run model1 (TensorFlow)\n",
    "        try:\n",
    "            tf_input = self.preprocess_for_model1(pil_image)\n",
    "            features = self.feature_extractor.predict(tf_input)\n",
    "            model1_probs = self.tf_model.predict(features)[0]\n",
    "            model1_class_idx = np.argmax(model1_probs)\n",
    "            model1_confidence = model1_probs[model1_class_idx]\n",
    "            model1_class = self.class_names_model1[model1_class_idx]\n",
    "        except Exception as e:\n",
    "            print(\"TensorFlow prediction error:\", e)\n",
    "            model1_class = \"Error\"\n",
    "            model1_confidence = 0.0\n",
    "            model1_probs = []\n",
    "        \n",
    "        # Run model2 (PyTorch)\n",
    "        try:\n",
    "            pt_input = self.preprocess_for_model2(pil_image)\n",
    "            with torch.no_grad():\n",
    "                model2_output = self.torch_model(pt_input)\n",
    "            model2_probs = F.softmax(model2_output, dim=-1)[0]\n",
    "            model2_class_idx = model2_probs.argmax(-1).item()\n",
    "            model2_confidence = model2_probs[model2_class_idx].item()\n",
    "            model2_class = self.class_names_model2[model2_class_idx]\n",
    "        except Exception as e:\n",
    "            print(\"PyTorch prediction error:\", e)\n",
    "            model2_class = \"Error\"\n",
    "            model2_confidence = 0.0\n",
    "            model2_probs = []\n",
    "        \n",
    "        return {\n",
    "            'model1': {\n",
    "                'class': model1_class,\n",
    "                'confidence': float(model1_confidence),\n",
    "                'all_probs': model1_probs.tolist() if len(model1_probs) > 0 else []\n",
    "            },\n",
    "            'model2': {\n",
    "                'class': model2_class,\n",
    "                'confidence': model2_confidence,\n",
    "                'all_probs': model2_probs.tolist() if torch.is_tensor(model2_probs) else []\n",
    "            },\n",
    "            'combined': self.combine_results(\n",
    "                model1_class, model1_confidence,\n",
    "                model2_class, model2_confidence\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def save(self, path):\n",
    "        \"\"\"Save the complete model with all weights in a single file\"\"\"\n",
    "        # Convert models to bytes\n",
    "        tf_model_bytes = None\n",
    "        if self._tf_model is not None:\n",
    "            with open(\"temp_tf_model.keras\", \"wb\") as f:\n",
    "                self._tf_model.save(f.name)\n",
    "            with open(\"temp_tf_model.keras\", \"rb\") as f:\n",
    "                tf_model_bytes = f.read()\n",
    "            os.remove(\"temp_tf_model.keras\")\n",
    "\n",
    "        torch_model_bytes = None\n",
    "        if self._torch_model is not None:\n",
    "            torch.jit.save(self._torch_model, \"temp_torch_model.pt\")\n",
    "            with open(\"temp_torch_model.pt\", \"rb\") as f:\n",
    "                torch_model_bytes = f.read()\n",
    "            os.remove(\"temp_torch_model.pt\")\n",
    "\n",
    "        # Save everything in one file\n",
    "        state = {\n",
    "            'tf_model_bytes': tf_model_bytes,\n",
    "            'torch_model_bytes': torch_model_bytes,\n",
    "            'class_names1': self.class_names_model1,\n",
    "            'class_names2': self.class_names_model2,\n",
    "            'conflict_rules': self.conflict_rules\n",
    "        }\n",
    "        \n",
    "        with open(path, 'wb') as f:\n",
    "            dill.dump(state, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\"Load the complete model from a single file\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            state = dill.load(f)\n",
    "        \n",
    "        # Reconstruct models from bytes\n",
    "        tf_model = None\n",
    "        if state['tf_model_bytes'] is not None:\n",
    "            with open(\"temp_reload_tf.keras\", \"wb\") as f:\n",
    "                f.write(state['tf_model_bytes'])\n",
    "            tf_model = tf.keras.models.load_model(\"temp_reload_tf.keras\")\n",
    "            os.remove(\"temp_reload_tf.keras\")\n",
    "\n",
    "        torch_model = None\n",
    "        if state['torch_model_bytes'] is not None:\n",
    "            with open(\"temp_reload_torch.pt\", \"wb\") as f:\n",
    "                f.write(state['torch_model_bytes'])\n",
    "            torch_model = torch.jit.load(\"temp_reload_torch.pt\")\n",
    "            torch_model.eval()\n",
    "            os.remove(\"temp_reload_torch.pt\")\n",
    "\n",
    "        return cls(\n",
    "            tf_model=tf_model,\n",
    "            torch_model=torch_model,\n",
    "            class_names1=state['class_names1'],\n",
    "            class_names2=state['class_names2'],\n",
    "            conflict_rules=state['conflict_rules']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73568fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabieash/miniconda3/envs/pytorch_env/lib/python3.9/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating combined model...\n"
     ]
    }
   ],
   "source": [
    "# First-time setup (only need to do this once)\n",
    "if not os.path.exists(\"combined_model.dill\"):\n",
    "        print(\"Creating combined model...\")\n",
    "        # Load original models\n",
    "        tf_model = tf.keras.models.load_model('final_model.h5')\n",
    "        torch_model = torch.jit.load('model_mobile_quantized.pt')\n",
    "        \n",
    "        # Define your class names and rules\n",
    "        CLASS_NAMES_MODEL1 = [\n",
    "            'Eczema', 'Melanoma', 'Atopic Dermatitis', \n",
    "            'Basal Cell Carcinoma', 'Melanocytic Nevi', 'Benign Keratosis'\n",
    "        ]\n",
    "        \n",
    "        CLASS_NAMES_MODEL2 = [\n",
    "            'Basal Cell Carcinoma', 'Darier_s Disease', 'Epidermolysis Bullosa Pruriginosa',\n",
    "            'Hailey-Hailey Disease', 'Herpes Simplex', 'Impetigo', 'Larva Migrans',\n",
    "            'Leprosy Borderline', 'Leprosy Lepromatous', 'Leprosy Tuberculoid',\n",
    "            'Lichen Planus', 'Lupus Erythematosus Chronicus Discoides', 'Melanoma',\n",
    "            'Molluscum Contagiosum', 'Mycosis Fungoides', 'Neurofibromatosis',\n",
    "            'Papilomatosis Confluentes And Reticulate', 'Pediculosis Capitis',\n",
    "            'Pityriasis Rosea', 'Porokeratosis Actinic', 'Psoriasis', 'Tinea Corporis',\n",
    "            'Tinea Nigra', 'Tungiasis', 'actinic keratosis', 'dermatofibroma', 'nevus',\n",
    "            'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma',\n",
    "            'vascular lesion'\n",
    "        ]\n",
    "        \n",
    "        CONFLICT_RULES = {\n",
    "            ('Eczema', 'Psoriasis'): 'Psoriasis',\n",
    "            ('Benign Keratosis', 'actinic keratosis'): 'actinic keratosis',\n",
    "            ('Melanocytic Nevi', 'Melanoma'): 'Melanoma',\n",
    "            ('Atopic Dermatitis', 'Eczema'): 'Eczema'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a018c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined model to combined_model.dill\n"
     ]
    }
   ],
   "source": [
    "# Create and save combined model\n",
    "combined_model = CombinedSkinModel(\n",
    "            tf_model=tf_model,\n",
    "            torch_model=torch_model,\n",
    "            class_names1=CLASS_NAMES_MODEL1,\n",
    "            class_names2=CLASS_NAMES_MODEL2,\n",
    "            conflict_rules=CONFLICT_RULES\n",
    "        )\n",
    "combined_model.save('combined_model.dill')\n",
    "print(\"Saved combined model to combined_model.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03895258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading combined model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 22:45:08.679437: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746301512.117313   10820 service.cc:152] XLA service 0x7f4e9c2640f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746301512.117422   10820 service.cc:160]   StreamExecutor device (0): Host, Default Version\n",
      "2025-05-03 22:45:12.125348: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1746301512.302233   10820 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
      "\n",
      "Prediction Results:\n",
      "ResNet50: Eczema (99.9%)\n",
      "DINOv2: Psoriasis (98.6%)\n",
      "Final: Psoriasis (99.9%) [Source: expert_rules]\n"
     ]
    }
   ],
   "source": [
    "# Normal usage (just load the combined model)\n",
    "print(\"Loading combined model...\")\n",
    "model = CombinedSkinModel.load('combined_model.dill')\n",
    "        \n",
    "# Make predictions\n",
    "result = model.predict('/home/rabieash/projects/GP/Psoriasis_copy.original.width-320.jpg')\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(f\"ResNet50: {result['model1']['class']} ({result['model1']['confidence']:.1%})\")\n",
    "print(f\"DINOv2: {result['model2']['class']} ({result['model2']['confidence']:.1%})\")\n",
    "print(f\"Final: {result['combined']['final_class']} ({result['combined']['confidence']:.1%}) [Source: {result['combined']['source']}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
